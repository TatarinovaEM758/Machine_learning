{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TatarinovaEM758/Machine_learning/blob/main/ML_3_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Перцептрон\n",
        "\n",
        "#### Цель работы\n",
        "\n",
        "Познакомиться с перцептроном как с моделью обучения с учителем в библиотеке sklearn.\n",
        "\n",
        "#### Содержание работы\n",
        "\n",
        "1. Сгенерируйте данные и обучите на них модель перцептрона.\n",
        "1. Просмотрите параметры модели, визуализируйте и улучшите ее работу.\n",
        "\n",
        "#### Методические указания\n",
        "\n",
        "Для тренировки работы с перцептроном создадим набор данных. Воспользуемся уже знакомыми функциями генерации данных. Сразу после создания визуализируем этот набор данных на диаграмме рассеяния:"
      ],
      "metadata": {
        "id": "Sox3uj8-Db_M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "nDLFBJJsDX9R",
        "outputId": "8dd941e0-683a-457f-ae4b-af90e5527c08"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'make_blobs' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-8d38628c093b>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mblob_centers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3.3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m X, y = make_blobs(n_samples=200, \n\u001b[0m\u001b[1;32m      3\u001b[0m                           \u001b[0mcenters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblob_centers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                           \u001b[0mcluster_std\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                           random_state=0)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'make_blobs' is not defined"
          ]
        }
      ],
      "source": [
        "blob_centers = ([1, 1], [3, 4], [1, 3.3], [3.5, 1.8])\n",
        "X, y = make_blobs(n_samples=200,\n",
        "                          centers=blob_centers,\n",
        "                          cluster_std=0.5,\n",
        "                          random_state=0)\n",
        "\n",
        "X[:, 0] *= 1000\n",
        "\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y,  edgecolors='black',linewidth=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вы должны увидеть набор данных, состоящий из четырех кластеров, принадлежащий четырем классам:\n",
        "\n",
        "\n",
        "\n",
        "То есть мы имеем дело с задачей множественной классификации. Для перцептрона это не проблема, нейросеть это очень универсальная модель, она может работать нативно и в множественном режиме. Давайте создадим первую версию нашей нейросети:"
      ],
      "metadata": {
        "id": "rpdDDb11EZ6d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = MLPClassifier(hidden_layer_sizes=(6,),\n",
        "                    random_state=1).fit(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "I2jawK6EEbkC",
        "outputId": "d658ddb9-4f56-41a0-e5fb-2e4c6c714469"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'MLPClassifier' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-c6918a66361a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m clf = MLPClassifier(hidden_layer_sizes=(6,), \n\u001b[0m\u001b[1;32m      2\u001b[0m                     random_state=1).fit(X, y)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'MLPClassifier' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обратите внимание, что при создании мы задаем количество слоев и количество нейронов в каждом из них с помощью кортежа hidden_layer_sizes. В данном случае имеем один скрытый слой в 6 нейронов. Если мы не зададим этот аргумент, то его значение по умолчанию - (100,), то есть один слой со ста нейронами. Этого для первой моедли будет довольно много.\n",
        "\n",
        "Так как мы уже обучили модель, мы можем посмотреть значения весов нейронов, то есть внутренние параметры нейросети. Все они хранятся в поле coefs_, аналогично другим моделям машинного обучения в sklearn. Например, можно вывести веса отдельно для каждого слоя:"
      ],
      "metadata": {
        "id": "_8J0xS0OElv-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Веса между входным и скрытым слоем:\")\n",
        "print(clf.coefs_[0])\n",
        "print(\"\\nВеса между скрытым и выходным слоем:\")\n",
        "print(clf.coefs_[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "rBdJHXDOEmsm",
        "outputId": "e39fe4f9-aeab-4140-80cf-f546cc322d17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Веса между входным и скрытым слоем:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'clf' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-786c3feee33f>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Веса между входным и скрытым слоем:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoefs_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nВеса между скрытым и выходным слоем:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoefs_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'clf' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Веса между входным и скрытым слоем:\n",
        "[[-0.13186096  0.36276684 -0.87753229 -0.3544923  -0.62342741 -0.69458326]\n",
        " [-0.55527141 -0.28633324 -0.1793465   0.07807555 -0.14370807  0.32689274]]\n",
        "\n",
        "Веса между скрытым и выходным слоем:\n",
        "[[-0.4955391  -0.41463226  0.41301641  0.65040935 -0.25197168  0.26165608]\n",
        " [ 0.5134373   0.53925562 -0.57325313 -0.6379063  -0.4542433   0.51596208]\n",
        " [-0.55456344 -0.10522807  0.63360879  0.03543427  0.28300565 -0.25076137]\n",
        " [ 0.25356345  0.4604906  -0.66711811  0.3423877   0.70293671  0.33948522]\n",
        " [-0.29956981  0.3969661  -0.54770982 -0.0851425   0.58948128 -0.28122352]\n",
        " [-0.28935468 -0.51007606 -0.6656005   0.24156416 -0.39625967 -0.3203444 ]]"
      ],
      "metadata": {
        "id": "4A1gvMcxEytn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Либо по каждому нейрону отдельно:"
      ],
      "metadata": {
        "id": "74XOo7MrEsaB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(clf.coefs_)):\n",
        "    number_neurons_in_layer = clf.coefs_[i].shape[1]\n",
        "    for j in range(number_neurons_in_layer):\n",
        "        weights = clf.coefs_[i][:,j]\n",
        "        print(i, j, weights, end=\", \")\n",
        "        print()\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "taToVHPIFBZU",
        "outputId": "d7770a58-bef8-450a-f304-2e408eaa96f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'clf' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-6968422aafe8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoefs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mnumber_neurons_in_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoefs_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_neurons_in_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoefs_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\", \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'clf' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "0 0 [-0.09809877 -0.58903611],\n",
        "0 1 [ 0.33667051 -0.31219238],\n",
        "0 2 [-0.82024119 -0.22424296],\n",
        "0 3 [-0.29720839  0.11423652],\n",
        "0 4 [-0.56852789 -0.18324369],\n",
        "0 5 [-0.66056109  0.37321781],\n",
        "\n",
        "1 0 [-0.51316658 -0.24370005 -0.59713359 -0.5769702   0.34285864 -0.7006119 ],\n",
        "1 1 [-0.43365467  0.34328608 -0.67678056 -0.10221922 -0.25645017  0.35515533],\n",
        "1 2 [ 0.43189995  0.57835494 -0.46609801  0.75476969  0.33417991  0.80295119],\n",
        "1 3 [0.68148414 0.57889271 0.54011704 0.00610289 0.47281254 0.33880635],"
      ],
      "metadata": {
        "id": "PKRMRzzOFJmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обратите внимание, что судя по выведенной информации, на выходном слое у нас четыре нейрона. Это обусловлено тем, что в датасете четыре класса. Количество классов всегда определяет количество нейронов на выходном слое. А на входном слое у нас два нейрона. Это потому, что в датасете всего две атрибута.\n",
        "\n",
        "Веса нейронов смещения (bias) как и в других моделях хранятся в отдельном поле:"
      ],
      "metadata": {
        "id": "uwBcJw6iFKPy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Веса смещения для скрытого слоя:\")\n",
        "print(clf.intercepts_[0])\n",
        "print(\"\\nВеса смещения для выходного слоя:\")\n",
        "print(clf.intercepts_[1])"
      ],
      "metadata": {
        "id": "hw4zUsplFM74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Веса смещения для скрытого слоя:\n",
        "[-0.55752645  0.60978582 -0.8640854   0.33258994 -0.18652436  0.05696655]\n",
        "\n",
        "Веса смещения для выходного слоя:\n",
        "[-0.29413473  0.49414359 -0.60792984 -0.11888525]"
      ],
      "metadata": {
        "id": "VBzjCdclFR-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Давайте проанализируем, насколько хорошо работает наша модель. Для этого воспользуемся уже знакомой матрицей классификации:"
      ],
      "metadata": {
        "id": "6sogn78LFTXt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y, clf.predict(X))"
      ],
      "metadata": {
        "id": "O9rLUPoZFV_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array([[ 1,  0, 49,  0],\n",
        "       [ 0,  0, 50,  0],\n",
        "       [ 1,  0, 49,  0],\n",
        "       [ 0,  0, 50,  0]])"
      ],
      "metadata": {
        "id": "PZAf48YeFbj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Мы видим, что как будто модель работает не совсем корректно и делает много ошибок. Чтобы убедиться в этом, изобразим классификацию на графике:"
      ],
      "metadata": {
        "id": "iMUdAQVqFcNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X0 = np.linspace(X[:, 0].min()-1,X[:, 0].max()+1, X.shape[0])\n",
        "X1 = np.linspace(X[:, 1].min()-1,X[:, 1].max()+1, X.shape[0])\n",
        "X0_grid, X1_grid = np.meshgrid(X0, X1)\n",
        "\n",
        "y_predict = clf.predict(np.c_[X0_grid.ravel(),X1_grid.ravel()]).reshape(X0_grid.shape)\n",
        "plt.pcolormesh(X0_grid, X1_grid, y_predict)\n",
        "\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y,  edgecolors='black',linewidth=1)\n",
        "plt.xlabel('X1')\n",
        "plt.ylabel('X2')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qH7s9LM_F2u9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "На примере данного кода познакомьтесь со способом изображения границы принятия решений для множественной классификации. Мы видим довольно странную картину:\n",
        "\n",
        "\n",
        "Почти все точки модель относит к одному классу. А граница принятия решений почти всегда вертикальна. Что мы сделали не так? Для ответа на этот вопрос надо обратить внимание на подпись осей координат. Дело в том, что атрибуты в исходных данных имеют очень разные значения.\n",
        "X\n",
        "1\n",
        " измеряется в тысячах, а\n",
        "X\n",
        "2\n",
        " - в единицах. Это может стать проблемой для неекоторых моделей машинного обучения. И перцептрон - одна из них. Для корректной работы перцептрона данные нужно обязательно нормализовать.\n",
        "\n",
        "Для этого импортируем и воспользуемся объектом нормализации данных. Наример, таким:"
      ],
      "metadata": {
        "id": "C2IXEC8jF5gC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "X_scaled = scaler.transform(X)\n",
        "X_scaled = scaler.transform(X)"
      ],
      "metadata": {
        "id": "insyUglBGAOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Давайте еще раз изобразим точки на графике, чтобы понять, как нормализация преобразовала наш датасет:\n",
        "\n",
        "\n",
        "\n",
        "Само распределение как будто не изменилось, но обратите внимание на значения по осям. Теперь наш датасет имеет одинаковую размерность. Данные как будто \"ужались\" по горизонтали. Давайте посмотрим, повлияет ли это на качество обучения. Переобучим модель и выведем матрицу классификации:"
      ],
      "metadata": {
        "id": "8ASMfqijGDcn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array([[22,  0, 11, 17],\n",
        "       [ 0, 38,  0, 12],\n",
        "       [ 0,  3, 45,  2],\n",
        "       [ 0,  5,  0, 45]])"
      ],
      "metadata": {
        "id": "4SrOE5amGEOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Мы видим совершенно другую картину. Стало значительно лучше. Для большей уверенности изобразим классификацию на графике:\n",
        "\n",
        "\n",
        "\n",
        "Мы видим, что регионы сооветствующих классов уже гораздо ближе к точкам обучающей выборки. При этом модель все еще делает довольно много ошибок. Как можно просто ее улучшить? вы могли обратить внимание, что при обучении модель выдавал предупреждение о раннем прерывании обучения. Мы уже сталкивались с такой ситуацией. Можно просто увеличить лимит итераций алгоритма обучения:"
      ],
      "metadata": {
        "id": "J75QMPqcGGao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = MLPClassifier(hidden_layer_sizes=(6,), max_iter=10_000, verbose=True).fit(X_scaled, y)"
      ],
      "metadata": {
        "id": "WalA0-LuGKj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Заодно здесь мы применим еще один аргумент конструктора объекта перцептрона - verbose. Он позволяет вывести подробную информацию про обучение модели. Проанализируйте полученную информацию и сделайте вывод.\n",
        "\n",
        "Теперь можно вывести матрицу классификации. Сразу видно, что опять стало значительно лучше:"
      ],
      "metadata": {
        "id": "Bph5AtYuGNR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array([[50,  0,  0,  0],\n",
        "       [ 0, 50,  0,  0],\n",
        "       [ 2,  3, 45,  0],\n",
        "       [ 0,  1,  0, 49]])"
      ],
      "metadata": {
        "id": "vLrjykgQGQT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Этот вывод подтверждает и визуализация модели:\n",
        "\n",
        "\n",
        "\n",
        "Для дальнейшего повышения точности можно увеличить количество скрытых слоев. Тогда получится уже глубокая нейросеть. Например, обучим перцептрон с тремя слоями:"
      ],
      "metadata": {
        "id": "XmqlxpQvGXyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = MLPClassifier(hidden_layer_sizes=(6, 6, 6), max_iter=10_000).fit(X_scaled, y)"
      ],
      "metadata": {
        "id": "k-PA6nveGYaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Из графика видно, что граница принятия решений еще больше соответствует обучающей выборке. Постройте матрицу классификации этой модели самостоятельно.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_Kv4MNwIGbGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задания для самостоятельного выполнения\n",
        "1. Создайте однослойный перцептрон с 1, 2, 10 и 100 нейронами. Сравние их точность\n",
        "и сделайте вывод о достаточном количестве нейронов.\n",
        "2. Создайте и оцените модель с двумя, тремя и десятью скрытыми слоями с одинаковым количеством нейронов. Сравните их точность и сделайте вывод о достаточном количестве слоев.\n",
        "3. Для глубокой модели выведите веса всех нейронов на всех слоях. Выведите значения векторов весов смещения.\n",
        "4. Постройте и оцените модель с большим количеством нейронов и слоев. Замерьте время выполнения обучения, сравните со временем обучения более простых моделей.\n",
        "5. Постройте и оцените модель классификации с помощью перцептрона на датасете, который вы использовали на контрольной по классификиации (если вы ее не выполняли, возьмите любой датасет из раздела \"real world datasets\" в библиотеке sklearn).\n",
        "6. Постройте и оцените модель регрессии с помощью перцептрона на датасете, который вы использовали на контрольной по регрессии."
      ],
      "metadata": {
        "id": "LrHDt5LdGlu6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Создайте однослойный перцептрон с 1, 2, 10 и 100 нейронами. Сравние их точность и сделайте вывод о достаточном количестве нейронов."
      ],
      "metadata": {
        "id": "cgv8cZWGHfEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Загружаем данные Iris\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Разделяем данные на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Списки для хранения результатов\n",
        "results = []\n",
        "\n",
        "# Определяем количество нейронов\n",
        "neurons = [1, 2, 10, 100]\n",
        "\n",
        "for n in neurons:\n",
        "    # Создаем однослойный перцептрон\n",
        "    model = MLPClassifier(hidden_layer_sizes=(n,), max_iter=1000, random_state=42)\n",
        "\n",
        "    # Обучаем модель\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Предсказываем на тестовой выборке\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Вычисляем точность\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    results.append((n, accuracy))\n",
        "\n",
        "# Печатаем результаты\n",
        "for n, acc in results:\n",
        "    print(f\"Количество нейронов: {n}, Точность: {acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfD3cOwcHfcJ",
        "outputId": "2b7c15b8-26ff-45ce-f9db-e60b43c0b60d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество нейронов: 1, Точность: 0.8667\n",
            "Количество нейронов: 2, Точность: 0.8667\n",
            "Количество нейронов: 10, Точность: 0.9667\n",
            "Количество нейронов: 100, Точность: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Низкое количество нейронов (1-2): Перцептрон с одним или двумя нейронами может показать неплохие результаты на простых задачах, но, как правило, его точность недостаточно высока для более сложных задач.\n",
        "\n",
        "2. Умеренное количество нейронов (10): Увеличение числа нейронов улучшает способность модели к обучению, что обычно приводит к повышению точности.\n",
        "\n",
        "3. Слишком большое количество нейронов (100): Здесь наблюдается потенциальная проблема переобучения, особенно если данных недостаточно. Однако на простых, хорошо разделяемых данных, таких как Iris, точность может оставаться высокой."
      ],
      "metadata": {
        "id": "pcaNxG8mHsW6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Создайте и оцените модель с двумя, тремя и десятью скрытыми слоями с одинаковым количеством нейронов. Сравните их точность и сделайте вывод о достаточном количестве слоев."
      ],
      "metadata": {
        "id": "P-GxXPEyIAWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Загрузка данных\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Функция для создания модели\n",
        "def create_model(num_layers):\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.InputLayer(input_shape=(X.shape[1],)))\n",
        "    for _ in range(num_layers):\n",
        "        model.add(keras.layers.Dense(64, activation='relu'))\n",
        "    model.add(keras.layers.Dense(3, activation='softmax'))  # 3 класса для Iris\n",
        "    return model\n",
        "\n",
        "# Обучение и оценка моделей\n",
        "results = {}\n",
        "for num_layers in [2, 3, 10]:\n",
        "    model = create_model(num_layers)\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.fit(X_train, y_train, epochs=100, verbose=0)\n",
        "    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "    results[num_layers] = test_accuracy\n",
        "\n",
        "# Вывод результатов\n",
        "print(\"Точности моделей с различным количеством слоев:\")\n",
        "for num_layers, accuracy in results.items():\n",
        "    print(f\"Скрытых слоев: -> Точность: {accuracy:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWnFtteoI4JN",
        "outputId": "6b68930b-f065-49c6-97f4-a4e6e76909d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Точности моделей с различным количеством слоев:\n",
            "Скрытых слоев: -> Точность: 0.9667\n",
            "Скрытых слоев: -> Точность: 0.9667\n",
            "Скрытых слоев: -> Точность: 0.9667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "При анализе точности моделей можно сделать следующие выводы:\n",
        "\n",
        "1. **Слишком мало слоев**: Если количество слоев слишком маленькое (например, 2), модель может быть недостаточно мощной для захвата сложных зависимостей в данных.\n",
        "\n",
        "2. **Оптимальное количество слоев**: При увеличении числа слоев (например, до 3 или 4) может наблюдаться повышение точности, если данные достаточно сложные.\n",
        "\n",
        "3. **Слишком много слоев**: После определенного момента (например, 10 слоев) точность может не увеличиваться или даже снижаться, что может быть связано с переобучением и трудностью в оптимизации более сложной модели.\n",
        "\n",
        "Таким образом, идеальное количество слоев зависит от конкретных данных и задачи, и оптимальное решение обычно требует экспериментов и кросс-валидации."
      ],
      "metadata": {
        "id": "0awhRTLdJrV1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Для глубокой модели выведите веса всех нейронов на всех слоях. Выведите значения векторов весов смещения."
      ],
      "metadata": {
        "id": "NucNb_drJt1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Пример создания простой модели\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(32,)),  # Входной слой\n",
        "    keras.layers.Dense(64, activation='relu'),                    # Скрытый слой\n",
        "    keras.layers.Dense(10, activation='softmax')                  # Выходной слой\n",
        "])\n",
        "\n",
        "# Компиляция модели\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Предположим, модель уже обучена\n",
        "\n",
        "# Получаем веса и смещения для каждого слоя\n",
        "for layer in model.layers:\n",
        "    weights, biases = layer.get_weights()  # Получаем веса и смещения\n",
        "    print(f\"Layer: {layer.name}\")\n",
        "    print(f\"Weights shape: {weights.shape}\")\n",
        "    print(weights)\n",
        "    print(f\"Biases shape: {biases.shape}\")\n",
        "    print(biases)\n",
        "    print(\"-\" * 40)  # Разделитель для удобства чтения"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRfdBY7jJ383",
        "outputId": "ece32bb7-c43b-4fb7-c8b6-a06cdb093d11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer: dense_18\n",
            "Weights shape: (32, 64)\n",
            "[[ 0.14744031 -0.1288696  -0.2449466  ... -0.14188051  0.16493642\n",
            "   0.22115642]\n",
            " [-0.13016915 -0.06086582 -0.1343059  ...  0.2187028   0.05806601\n",
            "   0.01879668]\n",
            " [-0.23085725  0.05213183 -0.19977772 ... -0.12639946 -0.19202214\n",
            "   0.06983089]\n",
            " ...\n",
            " [ 0.07923406 -0.14097947 -0.12072426 ...  0.1784687   0.12230533\n",
            "   0.16465646]\n",
            " [ 0.11793143  0.17105836  0.2079876  ...  0.12940389  0.23902172\n",
            "  -0.1489793 ]\n",
            " [-0.17862481  0.20256758  0.20135349 ... -0.2415781  -0.0029906\n",
            "  -0.2177077 ]]\n",
            "Biases shape: (64,)\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "----------------------------------------\n",
            "Layer: dense_19\n",
            "Weights shape: (64, 64)\n",
            "[[ 0.1831684   0.17487486  0.01945257 ... -0.13368809 -0.09582891\n",
            "  -0.00688191]\n",
            " [-0.14622751  0.17976184  0.16504769 ...  0.21449561  0.1493945\n",
            "   0.20397817]\n",
            " [ 0.20643045  0.1415322  -0.1886763  ... -0.09309754 -0.18570042\n",
            "   0.07708816]\n",
            " ...\n",
            " [ 0.20960818 -0.14531928 -0.1372036  ... -0.17511843 -0.12961751\n",
            "   0.08151214]\n",
            " [-0.17533389  0.07005562  0.21116252 ... -0.05745251 -0.19826533\n",
            "  -0.16744459]\n",
            " [-0.09663835  0.15229942 -0.131479   ...  0.07841836 -0.15418822\n",
            "  -0.1616925 ]]\n",
            "Biases shape: (64,)\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "----------------------------------------\n",
            "Layer: dense_20\n",
            "Weights shape: (64, 10)\n",
            "[[-2.55728662e-02 -1.70592189e-01 -1.81459546e-01 -8.25869143e-02\n",
            "  -1.84722006e-01  1.80396199e-01 -9.78419334e-02  2.71326900e-02\n",
            "   5.92365265e-02  2.49917179e-01]\n",
            " [-2.27861717e-01  1.23368353e-01 -7.45295733e-02 -1.99395493e-01\n",
            "  -2.83814311e-01 -1.50523648e-01 -6.93604946e-02  1.75418347e-01\n",
            "  -9.42429900e-03 -2.21935481e-01]\n",
            " [-1.22728765e-01  1.91008002e-01 -5.86804748e-03 -1.45923406e-01\n",
            "  -1.95359409e-01  1.28417343e-01 -8.86659771e-02 -8.13470632e-02\n",
            "   1.03060573e-01 -1.21551096e-01]\n",
            " [-2.44667113e-01 -7.69013166e-03  5.54070473e-02 -1.48035511e-01\n",
            "  -3.20203602e-02  2.90551782e-03 -1.59446850e-01 -2.80131757e-01\n",
            "  -1.89333245e-01 -1.99401200e-01]\n",
            " [-9.06698555e-02  5.04176021e-02 -1.86429620e-01 -4.90229726e-02\n",
            "  -9.93371904e-02  1.45853609e-01 -8.60906094e-02 -1.67469561e-01\n",
            "   2.33148366e-01  1.10394001e-01]\n",
            " [-2.70156801e-01  1.27192140e-02  6.04883432e-02 -6.79391026e-02\n",
            "  -1.16359085e-01  2.02779502e-01  2.67506987e-01  1.71561986e-01\n",
            "  -8.92938823e-02  2.51039475e-01]\n",
            " [-2.37390146e-01  5.20974398e-03  1.89511865e-01  2.62314647e-01\n",
            "  -2.77253449e-01  4.98300195e-02 -1.14588737e-01 -1.12137392e-01\n",
            "   8.64899158e-02  3.06287110e-02]\n",
            " [-2.31885642e-01  2.38693357e-02  2.39901572e-01  1.69202566e-01\n",
            "   1.69118345e-02 -2.41954267e-01  1.01104885e-01 -2.44203836e-01\n",
            "   2.53214985e-01 -1.82986557e-01]\n",
            " [ 1.94058537e-01  6.33115768e-02 -2.20828339e-01 -1.85041428e-01\n",
            "  -9.86504853e-02 -2.47818321e-01 -1.08459443e-01  1.04020298e-01\n",
            "   8.52047205e-02 -1.28011152e-01]\n",
            " [-2.37828106e-01 -2.22045600e-01 -1.09458357e-01  1.54645324e-01\n",
            "  -2.49262929e-01 -2.20814288e-01 -2.29945973e-01 -2.06327438e-01\n",
            "  -2.56770432e-01  2.26518959e-01]\n",
            " [-5.40131480e-02 -2.15276569e-01  2.22186744e-02 -6.36666417e-02\n",
            "   4.43053544e-02 -2.60568231e-01 -1.12717986e-01  1.42511249e-01\n",
            "  -2.69043416e-01  8.54335129e-02]\n",
            " [ 2.84608692e-01  1.08143359e-01  1.24797970e-01  2.45990962e-01\n",
            "   3.24187279e-02  3.63643765e-02 -1.84418485e-01  4.97493744e-02\n",
            "  -8.13196301e-02  1.81678623e-01]\n",
            " [-4.01620120e-02  7.96790123e-02  9.49388742e-03  4.05963659e-02\n",
            "  -1.37589961e-01 -7.83353597e-02  2.47608095e-01 -1.42755643e-01\n",
            "   7.82632828e-03  3.92835438e-02]\n",
            " [ 1.79164082e-01 -2.28135109e-01 -1.73668250e-01 -1.81689411e-01\n",
            "  -1.39690444e-01  2.45167166e-01  2.54986137e-01 -1.93494290e-01\n",
            "   2.75031477e-01 -1.18796572e-01]\n",
            " [-2.63635188e-01 -9.75768268e-02  1.31712317e-01  1.01368099e-01\n",
            "  -5.20485789e-02  2.25573450e-01  2.38906950e-01 -7.80170262e-02\n",
            "   2.57428378e-01  1.13641560e-01]\n",
            " [-4.65488881e-02  1.35291368e-01 -1.91041946e-01 -1.33398965e-01\n",
            "   9.61931646e-02  2.21743494e-01 -2.63339102e-01  4.89761829e-02\n",
            "   3.56508493e-02  9.72503424e-02]\n",
            " [ 9.77502167e-02 -7.95293897e-02  1.91995710e-01 -2.56265491e-01\n",
            "  -2.64400959e-01 -8.75328332e-02  2.23509580e-01  1.05135441e-01\n",
            "   1.86538517e-01 -1.90617293e-01]\n",
            " [ 1.50120646e-01 -6.18920177e-02  2.81726629e-01  1.11736298e-01\n",
            "  -1.73237145e-01 -2.13006839e-01  1.39744908e-01 -6.85323924e-02\n",
            "   1.48080856e-01  2.59423703e-01]\n",
            " [ 1.81800216e-01 -1.76116318e-01 -1.96685076e-01  1.88283205e-01\n",
            "   1.69418931e-01  2.07864046e-01  1.62824273e-01 -6.59356266e-02\n",
            "   4.19280231e-02 -2.55151302e-01]\n",
            " [-2.23872006e-01 -6.82675540e-02 -1.04528114e-01  2.65212268e-01\n",
            "   2.27144390e-01  1.26318753e-01 -1.24918878e-01  3.28018963e-02\n",
            "   1.40765876e-01 -9.10054296e-02]\n",
            " [ 2.43979007e-01  1.87891632e-01 -2.75251538e-01 -9.54617411e-02\n",
            "  -9.75205451e-02 -1.17844149e-01  1.73678696e-02 -2.68587351e-01\n",
            "   1.71550214e-02  2.60677189e-01]\n",
            " [ 2.14476585e-02 -2.62911826e-01 -1.97657391e-01 -2.52591044e-01\n",
            "   1.20712399e-01  2.51032203e-01 -2.14041740e-01 -1.46101147e-01\n",
            "  -9.62457955e-02 -7.84807801e-02]\n",
            " [ 1.36488378e-02 -2.09736973e-01  4.29818630e-02  2.57584065e-01\n",
            "  -1.13299936e-01  2.93391347e-02 -1.13065243e-02  8.75415206e-02\n",
            "  -2.12104261e-01  1.18045449e-01]\n",
            " [-3.40359807e-02  7.50846863e-02  2.00577378e-01 -6.57254457e-02\n",
            "   8.47114325e-02  1.88165814e-01  2.37666935e-01 -9.91479754e-02\n",
            "   4.33126092e-02  1.88907176e-01]\n",
            " [ 1.13789886e-01  4.42993939e-02 -1.02804005e-01  3.67220938e-02\n",
            "  -1.22932374e-01 -2.35451445e-01  1.57987446e-01  2.06358463e-01\n",
            "  -1.95422679e-01  2.36671358e-01]\n",
            " [-2.85370350e-02 -1.80337131e-02 -1.02691650e-01 -9.77806300e-02\n",
            "   8.29388499e-02  2.72133619e-01 -2.13413030e-01  1.72813654e-01\n",
            "  -2.36893535e-01  7.69045949e-03]\n",
            " [-1.37591526e-01 -1.65796787e-01 -2.78369486e-01  1.19940579e-01\n",
            "  -2.84250081e-02 -2.46578395e-01 -2.24714920e-01  5.58060408e-03\n",
            "  -8.27527046e-02 -7.46071637e-02]\n",
            " [ 3.44005525e-02  2.75814563e-01 -1.02488324e-01 -8.30495805e-02\n",
            "  -1.28885627e-01  1.34608686e-01 -1.51245028e-01 -2.24651441e-01\n",
            "   7.83625841e-02  1.16926849e-01]\n",
            " [-1.17305249e-01  1.60103470e-01  2.78556854e-01  1.17170364e-01\n",
            "   6.82199001e-02  6.05720282e-03 -2.77492970e-01  1.72016770e-01\n",
            "  -1.11226052e-01 -1.57080978e-01]\n",
            " [ 2.12382525e-01 -1.63403630e-01 -3.65066528e-03  6.35200143e-02\n",
            "  -2.52662599e-02 -5.04734814e-02  1.30424887e-01  2.75134295e-01\n",
            "  -6.28136098e-02  8.48722458e-03]\n",
            " [ 1.15225315e-02 -1.30600244e-01 -1.75612792e-01  1.95374817e-01\n",
            "  -1.40756577e-01 -1.62451863e-02  2.69168615e-02 -7.37853646e-02\n",
            "   1.28264457e-01 -1.49182692e-01]\n",
            " [-1.79754704e-01  1.53436750e-01 -1.19851902e-01 -2.08389640e-01\n",
            "  -2.65137285e-01 -2.32155979e-01 -4.04024869e-02 -1.65865958e-01\n",
            "   1.97831333e-01  2.63456404e-02]\n",
            " [-2.36198962e-01  4.47492898e-02  3.43681574e-02 -1.79001138e-01\n",
            "  -2.09907085e-01  8.70358348e-02 -2.29955286e-01 -1.07548162e-01\n",
            "  -2.41395950e-01  1.85445249e-01]\n",
            " [-7.09899068e-02 -1.44384563e-01  6.05855584e-02 -2.40560293e-01\n",
            "   1.74697727e-01 -2.79835016e-01 -3.86570543e-02  1.43833786e-01\n",
            "  -5.28747886e-02  1.38495654e-01]\n",
            " [ 1.10897958e-01  9.99813974e-02  1.51575595e-01 -6.89500421e-02\n",
            "  -2.06746176e-01 -6.04231656e-02  3.00643444e-02  1.81908906e-01\n",
            "  -1.92926824e-01  1.58049405e-01]\n",
            " [-6.34153187e-02  1.36166453e-01  9.10425186e-03  1.76757276e-02\n",
            "  -2.71237671e-01  2.43868738e-01 -4.52599376e-02 -4.96137440e-02\n",
            "   1.88760161e-02  4.20281589e-02]\n",
            " [ 1.86279535e-01 -1.09056324e-01  3.95185053e-02  3.32969427e-03\n",
            "  -1.20993868e-01 -2.42048025e-01 -2.44535208e-02 -2.61097908e-01\n",
            "  -2.30492279e-01 -2.36053213e-01]\n",
            " [-8.93420875e-02 -7.38992244e-02  1.20644987e-01  2.05785036e-04\n",
            "   1.50594652e-01  2.23369896e-02 -3.90633941e-03 -6.19835407e-02\n",
            "   6.78281784e-02  1.98135525e-01]\n",
            " [-1.20559379e-01  1.63248092e-01 -3.42035294e-02 -2.36314237e-02\n",
            "   1.03955209e-01  1.81246489e-01  2.78049201e-01 -2.79597461e-01\n",
            "  -2.14156061e-01  1.36568695e-01]\n",
            " [-2.68886864e-01  2.84637958e-01 -1.28179446e-01  1.69394016e-01\n",
            "  -1.06016248e-01 -1.88012868e-01  1.21590137e-01  1.43186808e-01\n",
            "   3.70943844e-02 -5.24107665e-02]\n",
            " [-1.57063305e-02 -1.19723320e-01  8.57470930e-02 -2.65184492e-01\n",
            "   2.28101283e-01  2.08253860e-02  2.51682967e-01  1.33404732e-01\n",
            "  -1.36268303e-01 -7.55632520e-02]\n",
            " [ 2.03231484e-01  2.75729030e-01  1.19589776e-01 -6.97095841e-02\n",
            "   2.43052214e-01  2.67126709e-01 -7.83695132e-02  6.13719225e-04\n",
            "  -1.77029371e-01 -2.52336532e-01]\n",
            " [-9.12256688e-02 -8.24406147e-02  8.48350525e-02  1.01861030e-01\n",
            "  -2.75230646e-01  1.58077776e-02  9.07752812e-02  1.22240931e-01\n",
            "  -1.95682168e-01  9.97768939e-02]\n",
            " [-1.75630376e-01  1.76328540e-01  1.36358440e-01  2.61987835e-01\n",
            "   1.39660776e-01 -2.63140053e-01 -4.03441042e-02  2.62858540e-01\n",
            "  -9.69808251e-02  2.31652766e-01]\n",
            " [-2.76222289e-01  2.20887929e-01 -6.31030202e-02 -2.00210154e-01\n",
            "  -1.38246045e-01  8.10482204e-02 -1.01450771e-01  3.72017026e-02\n",
            "   2.68338174e-01  5.73524237e-02]\n",
            " [-1.14621937e-01  2.27910072e-01 -2.42168516e-01  2.11827874e-01\n",
            "  -2.61703670e-01  2.28141248e-02  6.04448915e-02 -7.90674835e-02\n",
            "   9.99179780e-02 -1.97712392e-01]\n",
            " [ 6.37834072e-02  1.18712604e-01  8.02050829e-02 -5.74591756e-03\n",
            "  -1.90291435e-01  7.76234865e-02 -1.07231259e-01  1.36636198e-02\n",
            "   7.77477920e-02 -1.50910810e-01]\n",
            " [-1.08181089e-01  5.59321642e-02  1.07661068e-01  2.39887744e-01\n",
            "   2.52347380e-01 -5.26642054e-02 -2.64665484e-02 -2.50503868e-01\n",
            "   2.02974528e-01 -1.08035073e-01]\n",
            " [-2.62708634e-01  1.77136630e-01  2.61827022e-01  1.63513869e-01\n",
            "   1.45230532e-01  2.32189506e-01  2.30349630e-01 -1.49742991e-01\n",
            "   9.21965539e-02 -2.79404938e-01]\n",
            " [ 5.95909357e-03  2.58014768e-01  1.86958551e-01  1.51476264e-02\n",
            "   2.66218781e-02 -5.45020849e-02  1.98142529e-02  2.00006366e-01\n",
            "  -2.27928251e-01  1.92997217e-01]\n",
            " [ 1.48631305e-01 -8.51039737e-02 -1.66614771e-01  2.72817343e-01\n",
            "  -1.80723622e-01  2.02417314e-01  3.66430581e-02 -2.62762010e-02\n",
            "  -1.80089399e-01  4.14640009e-02]\n",
            " [ 5.33623099e-02 -2.17593566e-01  2.44933933e-01  2.23861009e-01\n",
            "   7.98660517e-03 -1.41860455e-01 -1.82048678e-02 -2.02171534e-01\n",
            "   2.21065879e-02 -1.44615173e-02]\n",
            " [ 2.67386109e-01 -2.47006506e-01  2.36914188e-01 -2.31689841e-01\n",
            "  -2.25410789e-01  1.14274889e-01  2.40469545e-01 -1.10750020e-01\n",
            "  -1.02880120e-01 -9.84530598e-02]\n",
            " [-2.31517613e-01  1.60251945e-01 -2.54884064e-02  6.84355199e-02\n",
            "   7.36629963e-03  2.21500397e-02  2.23503023e-01 -2.33077496e-01\n",
            "   6.43538237e-02 -2.57843763e-01]\n",
            " [ 9.20005441e-02  2.00491369e-01 -1.83846712e-01 -2.63319850e-01\n",
            "   1.95882976e-01 -2.30270207e-01  1.81237817e-01 -4.69380915e-02\n",
            "   4.74259555e-02 -1.51977241e-02]\n",
            " [ 2.33760804e-01 -1.98978111e-01 -2.38741413e-01 -1.85044020e-01\n",
            "   2.80905813e-01  4.55848575e-02 -1.88412607e-01 -2.11461425e-01\n",
            "   3.59863043e-02 -2.28252411e-01]\n",
            " [-6.38608038e-02  5.79419732e-02 -2.04470068e-01  1.99642330e-01\n",
            "   3.86828482e-02 -2.19471306e-01  2.57805735e-01 -2.03090012e-02\n",
            "  -1.59201920e-02  1.87800586e-01]\n",
            " [-1.35052070e-01  1.35965794e-01  1.69399381e-02 -4.42862809e-02\n",
            "  -1.40396297e-01  2.40087599e-01  3.43416929e-02 -2.14223623e-01\n",
            "  -5.74609041e-02 -2.28238225e-01]\n",
            " [ 1.63465619e-01 -1.36487648e-01  9.28384066e-03 -4.58143950e-02\n",
            "   9.92821157e-02  2.85838842e-02 -1.66770175e-01 -2.06293702e-01\n",
            "  -2.11872548e-01  3.11657786e-03]\n",
            " [-1.16839468e-01  3.82853746e-02 -2.76873678e-01  6.64280355e-02\n",
            "   2.00538933e-01  4.74774837e-02 -2.23633245e-01 -1.24437600e-01\n",
            "   2.50415951e-01  2.83660024e-01]\n",
            " [-2.39805281e-02  1.01532638e-01  6.81562126e-02  1.22236580e-01\n",
            "  -1.10394955e-02 -1.74280137e-01 -7.65358955e-02  8.17362070e-02\n",
            "  -1.59350038e-03  1.61814392e-02]\n",
            " [ 9.63753164e-02  2.22921282e-01 -9.94483232e-02  2.34000355e-01\n",
            "  -2.76954353e-01  1.53668344e-01 -1.78679615e-01  1.57410920e-01\n",
            "  -1.03915155e-01 -8.26261491e-02]\n",
            " [-1.40123993e-01  1.58636510e-01 -9.52005386e-04  8.11112821e-02\n",
            "  -1.73124582e-01  5.41910231e-02  7.66271949e-02  6.69679046e-03\n",
            "  -2.52086043e-01  1.60149038e-02]\n",
            " [ 1.43655181e-01 -1.66485175e-01  1.81638360e-01  2.74824470e-01\n",
            "  -4.38137054e-02  7.45487809e-02  7.56925642e-02 -5.76433837e-02\n",
            "  -1.94902048e-01  1.26225322e-01]]\n",
            "Biases shape: (10,)\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Постройте и оцените модель с большим количеством нейронов и слоев. Замерьте время выполнения обучения, сравните со временем обучения более простых моделей."
      ],
      "metadata": {
        "id": "LQspZhr1KWIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "\n",
        "# Загрузка данных MNIST\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "x_train, x_test = x_train.astype(\"float32\") / 255.0, x_test.astype(\"float32\") / 255.0\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "\n",
        "# Простой модель\n",
        "def build_simple_model():\n",
        "    model = keras.Sequential([\n",
        "        layers.Flatten(input_shape=(28, 28, 1)),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Большая модель\n",
        "def build_large_model():\n",
        "    model = keras.Sequential([\n",
        "        layers.Flatten(input_shape=(28, 28, 1)),\n",
        "        layers.Dense(512, activation='relu'),\n",
        "        layers.Dense(512, activation='relu'),\n",
        "        layers.Dense(512, activation='relu'),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Обучение простой модели\n",
        "simple_model = build_simple_model()\n",
        "start_time = time.time()\n",
        "simple_model.fit(x_train, y_train, epochs=5, batch_size=32, validation_split=0.2, verbose=0)\n",
        "simple_time = time.time() - start_time\n",
        "print(f\"Simple model training time: seconds\")\n",
        "\n",
        "# Обучение большой модели\n",
        "large_model = build_large_model()\n",
        "start_time = time.time()\n",
        "large_model.fit(x_train, y_train, epochs=5, batch_size=32, validation_split=0.2, verbose=0)\n",
        "large_time = time.time() - start_time\n",
        "print(f\"Large model training time: seconds\")\n",
        "\n",
        "# Оценка производительности\n",
        "simple_loss, simple_acc = simple_model.evaluate(x_test, y_test, verbose=0)\n",
        "large_loss, large_acc = large_model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "print(f\"Simple model accuracy: {simple_acc:.4f}\")\n",
        "print(f\"Large model accuracy: {large_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9v2FEaXKaIW",
        "outputId": "e983f7ac-4e7a-486c-ba0a-6a8724de18e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simple model training time: seconds\n",
            "Large model training time: seconds\n",
            "Simple model accuracy: 0.9767\n",
            "Large model accuracy: 0.9711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Большая модель будет обучаться значительно дольше по сравнению с простой моделью, а также ее точность может не сильно отличаться от точности простой модели. Это будет показывать, что увеличение количества параметров не всегда приводит к значительному увеличению производительности."
      ],
      "metadata": {
        "id": "PECEqBLwK_vD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Постройте и оцените модель классификации с помощью перцептрона на датасете, который вы использовали на контрольной по классификиации (если вы ее не выполняли, возьмите любой датасет из раздела \"real world datasets\" в библиотеке sklearn)."
      ],
      "metadata": {
        "id": "CTiqpSmELJi4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Загрузка датасета Iris\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Разделение данных на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Стандартизация данных\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Создание и обучение модели перцептрона\n",
        "perceptron = Perceptron(max_iter=1000, random_state=42)\n",
        "perceptron.fit(X_train, y_train)\n",
        "\n",
        "# Предсказания на тестовой выборке\n",
        "y_pred = perceptron.predict(X_test)\n",
        "\n",
        "# Оценка модели\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "print('Confusion Matrix:')\n",
        "print(conf_matrix)\n",
        "print('Classification Report:')\n",
        "print(class_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eC6e6lrLV42",
        "outputId": "430a88cb-cb1e-4eca-b67a-77e26f6ca543"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.93\n",
            "Confusion Matrix:\n",
            "[[10  0  0]\n",
            " [ 0  9  0]\n",
            " [ 0  2  9]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       0.82      1.00      0.90         9\n",
            "           2       1.00      0.82      0.90        11\n",
            "\n",
            "    accuracy                           0.93        30\n",
            "   macro avg       0.94      0.94      0.93        30\n",
            "weighted avg       0.95      0.93      0.93        30\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Мы получили значение точности (accuracy), матрицу ошибок (confusion matrix) и отчет о классификации (classification report), который включает такие метрики, как precision, recall и f1-score для каждого класса."
      ],
      "metadata": {
        "id": "mPQrsYvCLum0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Постройте и оцените модель регрессии с помощью перцептрона на датасете, который вы использовали на контрольной по регрессии."
      ],
      "metadata": {
        "id": "1CttsIthLY9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# 1. Загрузка данных\n",
        "data = pd.read_csv('Linear-regression.csv')\n",
        "\n",
        "# 2. Предобработка данных (при необходимости)\n",
        "# Например, удаление или заполнение пропусков\n",
        "data.fillna(data.mean(), inplace=True)\n",
        "\n",
        "# 3. Определение признаков и целевой переменной\n",
        "X = data.drop('Y', axis=1)\n",
        "y = data['Y']\n",
        "\n",
        "# 4. Разделение данных на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. Создание и обучение модели\n",
        "model = MLPRegressor(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 6. Оценка модели\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f'MAE: {mae}')\n",
        "print(f'MSE: {mse}')\n",
        "print(f'R²: {r2}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVY6YK6_L1Yy",
        "outputId": "d5d4e13f-cc52-49d8-ad12-9ccf165a5dc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 2.14770129704598\n",
            "MSE: 4.94337847190673\n",
            "R²: 0.9985512278661044\n"
          ]
        }
      ]
    }
  ]
}